ATOM-GPT Project - Complete Setup & Run Instructions
=======================================================

📋 OVERVIEW
-----------
This project consists of:
1. UNIFIED Backend (Flask) - Port 8000 (Auth + AI)
2. React Frontend - Port 3000
3. SQLite Database for user data & conversations
4. Local AI model with LM Studio integration

🔧 PREREQUISITES
-----------------
1. Python 3.8+ installed
2. Node.js 16+ and npm installed
3. CUDA-capable GPU (recommended for AI model)
4. LM Studio running on port 8080 (optional but recommended)

🚀 STEP-BY-STEP STARTUP GUIDE
===============================

1. START UNIFIED BACKEND (Port 8000)
-------------------------------------
cd "Z:\GIthub Raps\nanoGPT\backend"
python app.py

✅ Should show:
- "🚀 ATOM-GPT UNIFIED BACKEND"
- "🌐 Server: http://localhost:8000"
- "🔐 Demo account: admin@atomgpt.local / admin123"
- "🤖 AI Model: ✅ Loaded" (if available)
- "🔗 LM Studio: ✅ Available" (if connected)

2. START REACT FRONTEND (Port 3000)
------------------------------------
cd "Z:\GIthub Raps\nanoGPT\frontend"
npm start

✅ Should show:
- "webpack compiled with 1 warning"
- "No issues found"
- Opens browser at http://localhost:3000

3. VERIFY SYSTEM STATUS
-----------------------
Open browser to: http://localhost:3000

Check status indicators:
- 🟢 LM Studio: Connected
- 🟢 Model: Loaded
- 🟢 Authentication: Ready

🔐 DEMO LOGIN CREDENTIALS
==========================
Email: admin@atomgpt.local
Password: admin123

🧪 TESTING FUNCTIONALITY
=========================

1. AUTHENTICATION TEST:
   - Click login button
   - Use demo credentials above
   - Should see user profile in top-right

2. AI CHAT TEST:
   - Type a message in chat interface
   - Enable "LM Studio Enhancement" toggle
   - Should get AI-generated responses

3. CONVERSATION PERSISTENCE TEST:
   - Send multiple messages
   - Refresh page and login again
   - Conversations should be saved

4. COMPLETION TEST:
   - Go to completion interface
   - Enter a prompt
   - Should generate text completions

🗂️ API ENDPOINTS
=================

UNIFIED BACKEND API (Port 8000):
- POST /auth/login - User login
- POST /auth/register - User registration  
- GET /auth/me - Get current user
- GET /conversations - Get user conversations
- POST /conversations - Create conversation
- POST /conversations/{id}/messages - Add message
- GET /api/status - Model status
- GET /api/lm-studio/status - LM Studio status
- POST /api/chat - Send chat message
- POST /api/completion - Generate completion
- POST /api/lm-studio/reconnect - Reconnect LM Studio

🛠️ TROUBLESHOOTING
===================

BACKEND ISSUES:
- Port 8000 busy: Kill existing process or change port in backend/app.py
- Database errors: Delete backend/atom_gpt.db to reset database
- AI not loading: Check if interactive_chat.py and models are available

FRONTEND ISSUES:
- Port 3000 busy: Frontend will prompt to use different port (3001, 3002, etc.)
- TypeScript errors: Run "npm install" to ensure dependencies
- API connection errors: Verify backend server is running on port 8000

LM STUDIO ISSUES:
- Not connected: Start LM Studio application on port 8080
- Model not loaded: Load a model in LM Studio interface
- Performance issues: Ensure CUDA drivers installed for GPU acceleration

🐛 RECENT BUG FIXES
===================

✅ FIXED: Date Handling Error (July 3, 2025)
-------------------------------------------
Issue: "date.getTime is not a function" error in ChatSidebar and ChatHistory
Solution: Updated formatDate functions to handle both Date objects and date strings
Files Fixed:
- frontend/src/components/ChatSidebar.tsx
- frontend/src/components/ChatHistory.tsx  
- frontend/src/utils/chatStorage.ts (interface update)

The error occurred because database conversations return dates as strings,
while localStorage conversations use Date objects. The formatDate functions
now safely convert string dates to Date objects before using getTime().

✅ FIXED: Unified Backend Configuration (July 3, 2025)
----------------------------------------------------------
Issue: Complex dual-backend setup with auth (8000) and AI (8001) servers
Solution: Merged both backends into single unified server on port 8000
Files Changed:
- backend/app.py (added AI routes and imports)
- frontend/src/services/api.ts (unified to single backend)
- frontend/src/components/ChatInterface.tsx (use api service)
- frontend/src/components/CompletionInterface.tsx (use api service)
- frontend/src/App.tsx (status checks from port 8000)

Now only one backend server needs to be started, simplifying deployment
and reducing potential port conflicts. All functionality accessible on port 8000.

✅ FIXED: Missing meta.pkl and API Routes (July 3, 2025)
-----------------------------------------------------------
Issue 1: "No meta.pkl found, assuming GPT-2 encodings..." error
Solution: Copied meta.pkl from backend/data/DarkLyrics/ to correct relative path

Issue 2: API routes returning 404 despite being registered
Root Cause: The routes were properly defined but there was a path resolution issue
Solution: Fixed path resolution and restarted backend - all API endpoints now working

Files Fixed:
- Copied meta.pkl to correct location for model initialization
- Verified all API routes are working: /api/status, /api/chat, /api/completion

The AI model now loads with proper encodings and all API functionality is operational!

🔄 DEVELOPMENT WORKFLOW
========================

1. Start all three services (auth backend, AI backend, frontend)
2. Make code changes
3. Backends auto-reload with debug mode
4. Frontend hot-reloads automatically
5. Check browser console for any errors

💾 DATABASE MANAGEMENT
=======================

Database location: Z:\GIthub Raps\nanoGPT\backend\atom_gpt.db

Tables:
- users (authentication data)
- conversations (chat history)
- messages (individual messages)
- user_settings (user preferences)
- api_usage (usage tracking)

Reset database: Delete the .db file and restart auth backend

🚨 IMPORTANT NOTES
==================

1. Always start authentication backend (port 8000) FIRST
2. AI backend (port 8001) can be started independently
3. Frontend expects both backends to be running
4. Demo account is auto-created on first backend startup
5. LM Studio is optional but provides enhanced AI responses
6. GPU acceleration requires CUDA-compatible hardware
7. All conversation data is stored locally in SQLite

🎯 FEATURE HIGHLIGHTS
=====================

✅ User Authentication & Registration
✅ Persistent Conversation Storage  
✅ Real-time AI Chat with LM Studio
✅ Text Completion Generation
✅ User Profile Management
✅ Conversation History & Search
✅ Multiple Model Support
✅ GPU Acceleration (CUDA)
✅ Responsive Web Interface
✅ API-First Architecture

📞 QUICK START (TL;DR)
======================

OPTION 1: Use Startup Scripts (Recommended)
--------------------------------------------
Windows:
- Double-click: start-atomgpt.bat
- Or run: start-atomgpt.ps1 (PowerShell)

Git Bash/Linux/macOS:
- Run: ./start-atomgpt.sh

OPTION 2: Manual Start
----------------------
1. Terminal 1: cd backend && python app.py
2. Terminal 2: cd frontend && npm start  
3. Browser: http://localhost:3000
4. Login: admin@atomgpt.local / admin123
5. Chat away! 🎉

🚀 STARTUP SCRIPTS
==================

Three startup scripts are available for different environments:

1. start-atomgpt.bat (Windows Batch)
   - Works on all Windows systems
   - Uses Windows Terminal if available, otherwise cmd
   - Double-click to run

2. start-atomgpt.ps1 (PowerShell)
   - Modern Windows PowerShell script
   - Colored output and better Windows Terminal integration
   - Right-click → "Run with PowerShell"

3. start-atomgpt.sh (Bash)
   - Cross-platform bash script
   - Works on Git Bash, WSL, Linux, macOS
   - Run: chmod +x start-atomgpt.sh && ./start-atomgpt.sh

All scripts automatically:
- Open two separate terminal windows
- Start backend on port 8000
- Start frontend on port 3000
- Display connection URLs and login credentials

═══════════════════════════════════════════════════════════════════════════════

Last Updated: July 3, 2025
Project: ATOM-GPT with Authentication & LM Studio Integration
Status: ✅ Fully Functional
